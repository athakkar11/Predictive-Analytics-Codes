---
title: "Assignment 5A"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

Assignment 5A


```{r}
ebay = read.csv('/Users/anshitathakkar/Documents/Predictive Analytics/ebay.csv', stringsAsFactors = T)
ebay
```

How many rows are in the data?

```{r}
nrow(ebay)
```

q2: How many iPads are Black in color?


```{r}
library(dplyr)
library(caTools)
library(caret)
library(mgcv)

black_ipads <- subset(ebay, color == "Black")
black_ipad_count <- nrow(black_ipads)
print(black_ipad_count)

```


Another method:

```{r}
ebay |>
  filter(color == "Black")

sum(ebay$color == "Black")
```

Q3 
Which of the following iPads does this dataset contain? (Select all that apply)

```{r}
ebay$productline
unique(ebay$productline)
```

What is the uniqueID of the iPad with the highest startprice?

```{r}
ebay|>
  arrange(desc(startprice))


```

Assignment 5b

Q1
Split the Data into a train sample and a test sample using a seed of 196 such that 80% of the data is in the train sample. Use sample.split from library(caTools). Hereafter, we will only use the train sample for exploring and building the model. The test sample will only be utilized for evaluating the model.

How many rows are in the train sample?

```{r}
library(caTools)
library(dplyr)
set.seed(196)
split = sample.split(ebay$sold,SplitRatio = 0.8)
train = ebay[split,]
test = ebay[!split,]
nrow(train)
```

Q2 What is the median startprice of iPads that sold? (Do not include dollar sign. Only include numbers. E.g., 45.75 NOT $45.75)
Q 3 What is the median startprice of iPads that did not sell? 

```{r}
tapply(train$startprice,train$sold,median)
summary(tapply(train$startprice,train$sold,median))

train |>
  filter(sold == 0) |>
  summarise(median(startprice))

train |>
  filter(sold == 1) |>
  summarise(median(startprice))

```

Q4. Now, let us run a model to predict the variables that influence whether an iPad will be sold or not. Since the variable to be predicted only takes on two values, we will use a logistic regression model. Use the 'glm' function to build a model with 'sold' as the dependent variable and the following independent variables:

biddable, startprice, condition, cellular, carrier, color, storage, productline, noDescription, charCountDescription, upperCaseDescription, startprice_99end

Be sure to set family as 'binomial'.

What is the AIC?

```{r}
model1 = glm(sold~biddable+startprice+condition+cellular+carrier+color+storage+productline+noDescription+charCountDescription+upperCaseDescription+startprice_99end,data=train,family='binomial')
model1
```


Q5 Now, let us examine individual variables. Which of the following variables has a significant influence on whether an iPad is sold or not? (Select all that apply). Use a less conservative alpha of 0.10, i.e., compare p-value to 0.10.

Q6 Based on the results of the model, does a 99 ending for startprice increase the chance of an iPad being sold?

Q7 Based on the results of the model, does color of the iPad have an impact on whether an iPad is sold?

```{r}
summary(model1)
```


```{r}
model = glm(sold ~ biddable+startprice+condition+cellular+ 
            carrier+color+storage+productline+noDescription+ 
            charCountDescription+upperCaseDescription+startprice_99end,
            data = train,
            family = 'binomial')
summary(model)
```


Assignment 5c

 
 Q1
Simpler models are generally preferred to more complex models because they are less likely to overfit the data. So, let us drop out non-signficant variables from model1 above but keep variables that previous research or experience indicates should have an effect. So, estimate model2 with the following variables:

biddable, startprice, condition, storage, productline, upperCaseDescription, startprice_99end

What is the AIC?

(If you are surprised by a drop in AIC from model1 to model2, it is because AIC = 2k - 2LL = 2k + (-2LL). Now, -2LL is a measure of error and is similar to SSE (from linear regression). Simpler models such as model2 will always have -2LL that is larger than that for complex models like model1. To address this, AIC applies a penalty with the term 2k (where k is number of parameters or number of coefficients). For model1, 2k is much larger than 2k for model2.)


```{r}
model2 = glm(sold~biddable+startprice+condition+storage+productline+upperCaseDescription+startprice_99end,data=train,family='binomial')
summary(model2) #important to put summary in order to get the accurate aic score 


```

Q2 Based on the coefficient of upperCaseDescription, what advice would you give someone selling iPads on eBay?

```{r}
summary(model2)
#use less letters upper case because the upper case value is less than the intercept 
```

Q3 You will note that the data contains a number of factor variables. In order to model factor variables, they have to be dummy coded. Fortunately, glm and lm functions automatically dummy code factor variables and then run the dummy variables in the model. The first level is usually selected to be the baseline or reference variable to which each of the other levels is compared. Review the results of model2 and the coefficients of the variables. (After controlling for the effects of all other variables in the model), what sells better iPad3 or iPad 1?

(Now for yourself, after answering the above question, see if you can also find out how much better one sells than the other!)

#my answer is IPAD 3


Q4 If startprice goes up by $1, what will be the % reduction in the chance of selling an iPad. To interpret coefficients in logistic regression, you have to exponentiate the coefficient. E.g., exp(coefficient)

```{r}
library(randomForest)
library(dplyr)
library(caTools)
library(caret)
library(mgcv)


```

```{r}

predict(model2,newdata=data.frame(startprice=200,type='response'))

a = exp(model2$coef[1] + model2$coef[2]*200)/(1+exp(model2$coef[1] + model2$coef[2]*200)); a
b = exp(model2$coef[1] + model2$coef[2]*201)/(1+exp(model2$coef[1] + model2$coef[2]*201)); b

(b/a) 

```


Q4

If startprice goes up by $1, what will be the % reduction in the chance of selling an iPad. To interpret coefficients in logistic regression, you have to exponentiate the coefficient. E.g., exp(coefficient)
Question 4 options:

No change

1% # I chose this but I'm still not 100% sure on how to use this.

2%

5%


Q5 

Based on model2 (and controlling for the effects of all other variables), how much more (or less) likely is an iPad Air 1/2 to sell compared to an iPad 1?

Question 5 options:

iPad 1 is 6.6 times (or 560%) more likely to sell than iPad Air 1/2

iPad 1 is 1.88 times (or 88%) more likely to sell than iPad Air 1/2

iPad Air 1/2 is 6.6 times (or 560%) more likely to sell than iPad 1 # this is the correct answer 

iPad Air 1/2 is 1.88 times (or 88%) more likely to sell than iPad 1

Q 6

Question 6 (2 points) 
 
Now, let us run one more model called model_productline. For this model, predict the variable 'sold' using only 'productline'. Is the sign of the coefficient for iPad Air1/2 in this model the same as that in model2?

(Your conclusion may make you feel uncomfortable. The explanation lies in the fact that a multiple logistic regression controls for the effects of all other variables such as startprice but a simple logistic regression does not.)
Question 6 options:

Yes

No # my answer 

```{r}
model_productline= glm(sold~productline,data=train,family='binomial')
model_productline
```
```{r}
summary(model_productline)
```

Assignment 5D



Q1

Make predictions on the test set using model2. Place all the predictions in a variable "pred". Now, let us use the model to find out what is the probability of sale for an iPad with UniqueID 10940?

You could do this by running the following code.

```{r}
pred[test$UniqueID==10940]


pred <- predict(model2, newdata = test, type = "response")
probability_10940 <- pred[test$UniqueID == 10940]
probability_10940
```

Q 2 What is the accuracy of model2 on the test set? Use a threshold of 0.5.

```{r}
ct = table(sold = test$sold, predictions = as.integer(pred>0.5))
ct

accuracy = sum(ct[1,1],ct[2,2])/nrow(test); accuracy

```


Another method

```{r}
pred <- predict(model2, newdata = test, type = "response")
binary_pred <- ifelse(pred >= 0.5, 1, 0)
accuracy <- mean(binary_pred == test$sold)
accuracy
```


Q3 Let us see if there is any incremental benefit from using model2 over the baseline. Note, if you examine 'sold' in the train sample, it would be easy to see that most iPads don't sell. If one did not have any information on the independent variables one would predict an iPad will not sell. Baseline is the proportion (percent/100) of times one would be correct in the test sample if one were to make this assumption. 

```{r}
sum(train$sold)/nrow(train)

test[1-30,]

sum(test$sold==0)/nrow(test)

```

Another method

```{r}
baseline_accuracy <- mean(test$sold == 0)
pred <- predict(model2, newdata = test, type = "response")
binary_pred <- ifelse(pred >= 0.5, 1, 0)
model2_accuracy <- mean(binary_pred == test$sold)
baseline_accuracy
```

Q 4 Is model2 performing better than the baseline?

```{r}
#yes?
```

Q 5

The accuracy measure depends on the cut-value (or threshold) used. Hence a more popular measure is area under the curve (or AUC). AUC is computed by finding the area under the curve of a plot of Sensitivity vs. 1-Specificity. AUC is model performance measure that is independent of any particular threshold. You can do this by running the following code.

Ensure that your set of predictions is called 'pred' and your test sample is called test

  
# install.packages('ROCR')   # if you have not installed ROCR, be sure to install it first. 
library(ROCR)
ROCRpred = prediction(pred,test$sold)
as.numeric(performance(ROCRpred,"auc")@y.values) # auc measure
 
## construct plot
ROCRperf = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0,1,0.2),text.adj=c(-0.3,2),xlab="1 - Specificity",ylab="Sensitivity") # color coded, annotated ROC curve

```{r}
# install.packages('ROCR')   # if you have not installed ROCR, be sure to install it first. 
library(ROCR)
ROCRpred = prediction(pred,test$sold)
as.numeric(performance(ROCRpred,"auc")@y.values) # auc measure
 
## construct plot
ROCRperf = performance(ROCRpred,"tpr","fpr")
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0,1,0.2),text.adj=c(-0.3,2),xlab="1 - Specificity",ylab="Sensitivity") # color coded, annotated ROC curve
```


Q1. 0.02824507
Q2. 0.8064516
Q3. 0.5376344
Q4. Yes
Q5. 0.868968
